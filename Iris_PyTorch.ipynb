{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b70b4d",
   "metadata": {},
   "source": [
    "## Iris Dataset classification prediction using PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eebc779",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "Thanks for excellent tutorial for Pytorch!\n",
    "https://www.youtube.com/watch?v=lfQs6JEkhTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c11a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df38623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c994bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x107636eb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1239\n",
    "torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a99ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    torch.cuda.manual_seed(SEED)  #will it work?\n",
    "\n",
    "    \n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04e07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= ['slength','swidth','plength','pwidth'] + ['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9efabb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0f963f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   slength  150 non-null    float32\n",
      " 1   swidth   150 non-null    float32\n",
      " 2   plength  150 non-null    float32\n",
      " 3   pwidth   150 non-null    float32\n",
      " 4   class    150 non-null    float32\n",
      "dtypes: float32(5)\n",
      "memory usage: 3.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eac72a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slength</th>\n",
       "      <th>swidth</th>\n",
       "      <th>plength</th>\n",
       "      <th>pwidth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     slength  swidth  plength  pwidth  class\n",
       "112      6.8     3.0      5.5     2.1    2.0\n",
       "125      7.2     3.2      6.0     1.8    2.0\n",
       "113      5.7     2.5      5.0     2.0    2.0\n",
       "90       5.5     2.6      4.4     1.2    1.0\n",
       "37       4.9     3.6      1.4     0.1    0.0\n",
       "..       ...     ...      ...     ...    ...\n",
       "30       4.8     3.1      1.6     0.2    0.0\n",
       "115      6.4     3.2      5.3     2.3    2.0\n",
       "91       6.1     3.0      4.6     1.4    1.0\n",
       "27       5.2     3.5      1.5     0.2    0.0\n",
       "128      6.4     2.8      5.6     2.1    2.0\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1000f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df.index)\n",
    "new_indices = np.random.permutation(n)\n",
    "df = df.iloc[new_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7f1a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df ['class']\n",
    "X = df.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df5cf6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e94e07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1591729e+00, -1.3197948e-01,  9.9010795e-01,  1.1855671e+00],\n",
       "       [ 1.6438439e+00,  3.2841417e-01,  1.2742952e+00,  7.9067063e-01],\n",
       "       [-1.7367418e-01, -1.2829634e+00,  7.0592082e-01,  1.0539351e+00],\n",
       "       [-4.1600969e-01, -1.0527668e+00,  3.6489633e-01,  8.7762193e-04],\n",
       "       [-1.1430168e+00,  1.2492008e+00, -1.3402265e+00, -1.4470764e+00],\n",
       "       [-1.1430168e+00,  9.8217063e-02, -1.2833891e+00, -1.3154444e+00],\n",
       "       [-2.9484195e-01, -3.6217603e-01, -8.9803182e-02,  1.3250968e-01],\n",
       "       [ 3.1099743e-01, -5.9237313e-01,  5.3540844e-01,  8.7762193e-04],\n",
       "       [ 2.4920194e+00,  1.7095945e+00,  1.5016450e+00,  1.0539351e+00],\n",
       "       [ 6.8661921e-02,  3.2841417e-01,  5.9224612e-01,  7.9067063e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e938f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), y.to_numpy(),\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76607837",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape\n",
    "x_shape = X_train.shape\n",
    "y_shape = y_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52424826",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = x_shape[1]\n",
    "output_size = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f32a4b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3\n"
     ]
    }
   ],
   "source": [
    "print(input_size,output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b67ae2b",
   "metadata": {},
   "source": [
    "## Dataset Class\n",
    "\n",
    "The dataset class defines a class where data exists. It has two types, test dataset and train dataset. Each type will hold the corresponding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f050c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, data,label):\n",
    "        assert len(data) == len(label)\n",
    "        \n",
    "        self.data = torch.from_numpy(data)\n",
    "        self.label =torch.from_numpy(label)\n",
    "        \n",
    "    def __getitem__ (self,index):\n",
    "        return self.data[index], self.label[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0c3a42",
   "metadata": {},
   "source": [
    "#### Load data to dataloader dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a006eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = IrisDataset(X_train,y_train)\n",
    "test_data = IrisDataset(X_test,y_test)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size = 64,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size = 64,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab9c8c3",
   "metadata": {},
   "source": [
    "### Create neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3bce18",
   "metadata": {},
   "source": [
    "#### Attach to MPS (Metal), else CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c88c0a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49a673d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4faad3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisNeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.fn1 = nn.Linear(input_size,6)\n",
    "        self.fn2 = nn.Linear(6,output_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fn1(x))\n",
    "        x = self.fn2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d507409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IrisNeuralNetwork(\n",
       "  (fn1): Linear(in_features=4, out_features=6, bias=True)\n",
       "  (fn2): Linear(in_features=6, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = IrisNeuralNetwork()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a77ccb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9031,  0.1955,  1.9378],\n",
      "        [ 1.7876,  0.2963,  1.9375],\n",
      "        [ 1.1618,  0.2885,  2.1160],\n",
      "        [ 1.6410,  0.2266,  1.9201],\n",
      "        [ 1.6470, -0.0170,  1.9157]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(train_dataloader))\n",
    "x = x[:5].to(device)\n",
    "score = model(x)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c64819",
   "metadata": {},
   "source": [
    "## Loss Function and Optimizer\n",
    "\n",
    "Cross Entropy Loss and Adam Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "229ac064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01, weight_decay = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "623617dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    \n",
    "    for x,y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        n = x.size(0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        score = model(x)\n",
    "        y_long = y.type(torch.LongTensor)\n",
    "        loss = loss_function(score,y_long)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        predictions = score.max(1, keepdim=True)[1]\n",
    "        num_correct = predictions.eq(y.view_as(predictions)).sum().item()\n",
    "        \n",
    "    accuracy = num_correct /n\n",
    "    return loss, accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0fd1747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x,y in test_dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            n = x.size(0)\n",
    "\n",
    "            score = model(x)\n",
    "            y_long = y.type(torch.LongTensor)\n",
    "            loss = loss_function(score,y_long)\n",
    "\n",
    "            predictions = score.max(1, keepdim=True)[1]\n",
    "            num_correct = predictions.eq(y.view_as(predictions)).sum().item()\n",
    "        \n",
    "    accuracy = num_correct /n \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c244348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/80] Train loss:1.3220 acc:3.85% -- Test Loss:1.2136 acc:26.92%\n",
      "[1/80] Train loss:1.1661 acc:46.15% -- Test Loss:1.1273 acc:38.46%\n",
      "[2/80] Train loss:1.1361 acc:15.38% -- Test Loss:1.1329 acc:26.92%\n",
      "[3/80] Train loss:1.1405 acc:26.92% -- Test Loss:1.1172 acc:26.92%\n",
      "[4/80] Train loss:1.0984 acc:23.08% -- Test Loss:1.0635 acc:15.38%\n",
      "[5/80] Train loss:1.0407 acc:26.92% -- Test Loss:1.0143 acc:57.69%\n",
      "[6/80] Train loss:1.0012 acc:57.69% -- Test Loss:0.9879 acc:57.69%\n",
      "[7/80] Train loss:0.9836 acc:57.69% -- Test Loss:0.9775 acc:57.69%\n",
      "[8/80] Train loss:0.9766 acc:57.69% -- Test Loss:0.9722 acc:57.69%\n",
      "[9/80] Train loss:0.9720 acc:57.69% -- Test Loss:0.9675 acc:57.69%\n",
      "[10/80] Train loss:0.9681 acc:57.69% -- Test Loss:0.9639 acc:57.69%\n",
      "[11/80] Train loss:0.9659 acc:57.69% -- Test Loss:0.9616 acc:57.69%\n",
      "[12/80] Train loss:0.9637 acc:57.69% -- Test Loss:0.9573 acc:53.85%\n",
      "[13/80] Train loss:0.9566 acc:42.31% -- Test Loss:0.9458 acc:50.00%\n",
      "[14/80] Train loss:0.9405 acc:42.31% -- Test Loss:0.9252 acc:53.85%\n",
      "[15/80] Train loss:0.9160 acc:57.69% -- Test Loss:0.8988 acc:65.38%\n",
      "[16/80] Train loss:0.8882 acc:69.23% -- Test Loss:0.8716 acc:69.23%\n",
      "[17/80] Train loss:0.8615 acc:69.23% -- Test Loss:0.8470 acc:73.08%\n",
      "[18/80] Train loss:0.8383 acc:73.08% -- Test Loss:0.8264 acc:73.08%\n",
      "[19/80] Train loss:0.8195 acc:73.08% -- Test Loss:0.8098 acc:73.08%\n",
      "[20/80] Train loss:0.8047 acc:73.08% -- Test Loss:0.7963 acc:73.08%\n",
      "[21/80] Train loss:0.7925 acc:73.08% -- Test Loss:0.7850 acc:73.08%\n",
      "[22/80] Train loss:0.7822 acc:73.08% -- Test Loss:0.7747 acc:73.08%\n",
      "[23/80] Train loss:0.7720 acc:73.08% -- Test Loss:0.7637 acc:73.08%\n",
      "[24/80] Train loss:0.7603 acc:73.08% -- Test Loss:0.7503 acc:73.08%\n",
      "[25/80] Train loss:0.7453 acc:73.08% -- Test Loss:0.7337 acc:73.08%\n",
      "[26/80] Train loss:0.7272 acc:73.08% -- Test Loss:0.7148 acc:73.08%\n",
      "[27/80] Train loss:0.7075 acc:73.08% -- Test Loss:0.6956 acc:73.08%\n",
      "[28/80] Train loss:0.6884 acc:73.08% -- Test Loss:0.6773 acc:73.08%\n",
      "[29/80] Train loss:0.6709 acc:73.08% -- Test Loss:0.6608 acc:73.08%\n",
      "[30/80] Train loss:0.6552 acc:73.08% -- Test Loss:0.6462 acc:73.08%\n",
      "[31/80] Train loss:0.6414 acc:73.08% -- Test Loss:0.6330 acc:73.08%\n",
      "[32/80] Train loss:0.6290 acc:73.08% -- Test Loss:0.6211 acc:73.08%\n",
      "[33/80] Train loss:0.6175 acc:73.08% -- Test Loss:0.6095 acc:73.08%\n",
      "[34/80] Train loss:0.6060 acc:73.08% -- Test Loss:0.5977 acc:73.08%\n",
      "[35/80] Train loss:0.5941 acc:73.08% -- Test Loss:0.5857 acc:73.08%\n",
      "[36/80] Train loss:0.5819 acc:73.08% -- Test Loss:0.5737 acc:73.08%\n",
      "[37/80] Train loss:0.5698 acc:73.08% -- Test Loss:0.5619 acc:73.08%\n",
      "[38/80] Train loss:0.5582 acc:73.08% -- Test Loss:0.5507 acc:73.08%\n",
      "[39/80] Train loss:0.5474 acc:73.08% -- Test Loss:0.5404 acc:73.08%\n",
      "[40/80] Train loss:0.5375 acc:73.08% -- Test Loss:0.5310 acc:73.08%\n",
      "[41/80] Train loss:0.5284 acc:73.08% -- Test Loss:0.5222 acc:73.08%\n",
      "[42/80] Train loss:0.5199 acc:73.08% -- Test Loss:0.5138 acc:73.08%\n",
      "[43/80] Train loss:0.5116 acc:76.92% -- Test Loss:0.5054 acc:73.08%\n",
      "[44/80] Train loss:0.5032 acc:80.77% -- Test Loss:0.4970 acc:80.77%\n",
      "[45/80] Train loss:0.4947 acc:80.77% -- Test Loss:0.4885 acc:80.77%\n",
      "[46/80] Train loss:0.4861 acc:88.46% -- Test Loss:0.4799 acc:88.46%\n",
      "[47/80] Train loss:0.4775 acc:88.46% -- Test Loss:0.4715 acc:88.46%\n",
      "[48/80] Train loss:0.4692 acc:88.46% -- Test Loss:0.4633 acc:88.46%\n",
      "[49/80] Train loss:0.4611 acc:88.46% -- Test Loss:0.4553 acc:88.46%\n",
      "[50/80] Train loss:0.4533 acc:88.46% -- Test Loss:0.4473 acc:88.46%\n",
      "[51/80] Train loss:0.4452 acc:88.46% -- Test Loss:0.4393 acc:88.46%\n",
      "[52/80] Train loss:0.4372 acc:88.46% -- Test Loss:0.4315 acc:88.46%\n",
      "[53/80] Train loss:0.4295 acc:88.46% -- Test Loss:0.4240 acc:88.46%\n",
      "[54/80] Train loss:0.4222 acc:88.46% -- Test Loss:0.4169 acc:88.46%\n",
      "[55/80] Train loss:0.4152 acc:92.31% -- Test Loss:0.4101 acc:88.46%\n",
      "[56/80] Train loss:0.4086 acc:96.15% -- Test Loss:0.4036 acc:92.31%\n",
      "[57/80] Train loss:0.4022 acc:96.15% -- Test Loss:0.3972 acc:96.15%\n",
      "[58/80] Train loss:0.3958 acc:96.15% -- Test Loss:0.3908 acc:96.15%\n",
      "[59/80] Train loss:0.3894 acc:96.15% -- Test Loss:0.3844 acc:96.15%\n",
      "[60/80] Train loss:0.3830 acc:96.15% -- Test Loss:0.3781 acc:96.15%\n",
      "[61/80] Train loss:0.3767 acc:96.15% -- Test Loss:0.3719 acc:96.15%\n",
      "[62/80] Train loss:0.3705 acc:96.15% -- Test Loss:0.3658 acc:96.15%\n",
      "[63/80] Train loss:0.3645 acc:96.15% -- Test Loss:0.3598 acc:96.15%\n",
      "[64/80] Train loss:0.3585 acc:96.15% -- Test Loss:0.3540 acc:96.15%\n",
      "[65/80] Train loss:0.3527 acc:100.00% -- Test Loss:0.3482 acc:96.15%\n",
      "[66/80] Train loss:0.3469 acc:100.00% -- Test Loss:0.3424 acc:96.15%\n",
      "[67/80] Train loss:0.3412 acc:100.00% -- Test Loss:0.3368 acc:100.00%\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 80\n",
    "for epoch in range(max_epochs):\n",
    "    tr_loss, tr_acc = train()\n",
    "    eva_loss, eva_acc = evaluate()\n",
    "    \n",
    "        \n",
    "    print('[{}/{}] Train loss:{:.4f} acc:{:.2f}% -- Test Loss:{:.4f} acc:{:.2f}%'.format(\n",
    "        epoch, max_epochs, tr_loss,tr_acc*100, eva_loss, eva_acc*100\n",
    "    ))\n",
    "    \n",
    "    if eva_acc >= 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbbe535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
