{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac48973a",
   "metadata": {},
   "source": [
    "## Iris Dataset classification prediction using PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1434987",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "Thanks for excellent tutorial for Pytorch!\n",
    "https://www.youtube.com/watch?v=lfQs6JEkhTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87e0edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4dc5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5b017aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x105bb3ed0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1239\n",
    "torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a13088",
   "metadata": {},
   "source": [
    "### Run only if you have M1 Mac, otherwise skip this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ec00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    torch.cuda.manual_seed(SEED)  #will it work?\n",
    "    \n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "047ce9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= ['slength','swidth','plength','pwidth'] + ['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3958aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6152227a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   slength  150 non-null    float32\n",
      " 1   swidth   150 non-null    float32\n",
      " 2   plength  150 non-null    float32\n",
      " 3   pwidth   150 non-null    float32\n",
      " 4   class    150 non-null    float32\n",
      "dtypes: float32(5)\n",
      "memory usage: 3.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "848c7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df.index)\n",
    "new_indices = np.random.permutation(n)\n",
    "df = df.iloc[new_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a1bf9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df ['class']\n",
    "X = df.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e990ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7116156f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1591729e+00, -1.3197948e-01,  9.9010795e-01,  1.1855671e+00],\n",
       "       [ 1.6438439e+00,  3.2841417e-01,  1.2742952e+00,  7.9067063e-01],\n",
       "       [-1.7367418e-01, -1.2829634e+00,  7.0592082e-01,  1.0539351e+00],\n",
       "       [-4.1600969e-01, -1.0527668e+00,  3.6489633e-01,  8.7762193e-04],\n",
       "       [-1.1430168e+00,  1.2492008e+00, -1.3402265e+00, -1.4470764e+00],\n",
       "       [-1.1430168e+00,  9.8217063e-02, -1.2833891e+00, -1.3154444e+00],\n",
       "       [-2.9484195e-01, -3.6217603e-01, -8.9803182e-02,  1.3250968e-01],\n",
       "       [ 3.1099743e-01, -5.9237313e-01,  5.3540844e-01,  8.7762193e-04],\n",
       "       [ 2.4920194e+00,  1.7095945e+00,  1.5016450e+00,  1.0539351e+00],\n",
       "       [ 6.8661921e-02,  3.2841417e-01,  5.9224612e-01,  7.9067063e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3113531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), y.to_numpy(),\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd4914c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape\n",
    "x_shape = X_train.shape\n",
    "y_shape = y_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db60f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = x_shape[1]\n",
    "output_size = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9aaba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3\n"
     ]
    }
   ],
   "source": [
    "print(input_size,output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc6362",
   "metadata": {},
   "source": [
    "## Dataset Class\n",
    "\n",
    "The dataset class defines a class where data exists. It has two types, test dataset and train dataset. Each type will hold the corresponding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81b8dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, data,label):\n",
    "        assert len(data) == len(label)\n",
    "        \n",
    "        self.data = torch.from_numpy(data)\n",
    "        self.label =torch.from_numpy(label)\n",
    "        \n",
    "    def __getitem__ (self,index):\n",
    "        return self.data[index], self.label[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf3108",
   "metadata": {},
   "source": [
    "#### Load data to dataloader dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1546393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = IrisDataset(X_train,y_train)\n",
    "test_data = IrisDataset(X_test,y_test)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size = 64,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size = 64,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293fc692",
   "metadata": {},
   "source": [
    "### Create neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a69f9e",
   "metadata": {},
   "source": [
    "#### Attach to MPS (Metal), else CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b880d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09176a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd0cee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisNeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.fn1 = nn.Linear(input_size,6)\n",
    "        self.fn2 = nn.Linear(6,output_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fn1(x))\n",
    "        x = self.fn2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f17312e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IrisNeuralNetwork(\n",
       "  (fn1): Linear(in_features=4, out_features=6, bias=True)\n",
       "  (fn2): Linear(in_features=6, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = IrisNeuralNetwork()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efef01f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9031,  0.1955,  1.9378],\n",
      "        [ 1.7876,  0.2963,  1.9375],\n",
      "        [ 1.1618,  0.2885,  2.1160],\n",
      "        [ 1.6410,  0.2266,  1.9201],\n",
      "        [ 1.6470, -0.0170,  1.9157]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(train_dataloader))\n",
    "x = x[:5].to(device)\n",
    "score = model(x)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e472f786",
   "metadata": {},
   "source": [
    "## Loss Function and Optimizer\n",
    "\n",
    "Cross Entropy Loss and Adam Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ca26cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01, weight_decay = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c405044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    \n",
    "    for x,y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        n = x.size(0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        score = model(x)\n",
    "        y_long = y.type(torch.LongTensor)\n",
    "        loss = loss_function(score,y_long)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        predictions = score.max(1, keepdim=True)[1]\n",
    "        num_correct = predictions.eq(y.view_as(predictions)).sum().item()\n",
    "        \n",
    "    accuracy = num_correct /n\n",
    "    return loss, accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d0ecefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x,y in test_dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            n = x.size(0)\n",
    "\n",
    "            score = model(x)\n",
    "            y_long = y.type(torch.LongTensor)\n",
    "            loss = loss_function(score,y_long)\n",
    "\n",
    "            predictions = score.max(1, keepdim=True)[1]\n",
    "            num_correct = predictions.eq(y.view_as(predictions)).sum().item()\n",
    "        \n",
    "    accuracy = num_correct /n \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b41fed6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/80] Train loss:1.3220 acc:3.85% -- Test Loss:1.2136 acc:26.92%\n",
      "[1/80] Train loss:1.1661 acc:46.15% -- Test Loss:1.1273 acc:38.46%\n",
      "[2/80] Train loss:1.1361 acc:15.38% -- Test Loss:1.1329 acc:26.92%\n",
      "[3/80] Train loss:1.1405 acc:26.92% -- Test Loss:1.1172 acc:26.92%\n",
      "[4/80] Train loss:1.0984 acc:23.08% -- Test Loss:1.0635 acc:15.38%\n",
      "[5/80] Train loss:1.0407 acc:26.92% -- Test Loss:1.0143 acc:57.69%\n",
      "[6/80] Train loss:1.0012 acc:57.69% -- Test Loss:0.9879 acc:57.69%\n",
      "[7/80] Train loss:0.9836 acc:57.69% -- Test Loss:0.9775 acc:57.69%\n",
      "[8/80] Train loss:0.9766 acc:57.69% -- Test Loss:0.9722 acc:57.69%\n",
      "[9/80] Train loss:0.9720 acc:57.69% -- Test Loss:0.9675 acc:57.69%\n",
      "[10/80] Train loss:0.9681 acc:57.69% -- Test Loss:0.9639 acc:57.69%\n",
      "[11/80] Train loss:0.9659 acc:57.69% -- Test Loss:0.9616 acc:57.69%\n",
      "[12/80] Train loss:0.9637 acc:57.69% -- Test Loss:0.9573 acc:53.85%\n",
      "[13/80] Train loss:0.9566 acc:42.31% -- Test Loss:0.9458 acc:50.00%\n",
      "[14/80] Train loss:0.9405 acc:42.31% -- Test Loss:0.9252 acc:53.85%\n",
      "[15/80] Train loss:0.9160 acc:57.69% -- Test Loss:0.8988 acc:65.38%\n",
      "[16/80] Train loss:0.8882 acc:69.23% -- Test Loss:0.8716 acc:69.23%\n",
      "[17/80] Train loss:0.8615 acc:69.23% -- Test Loss:0.8470 acc:73.08%\n",
      "[18/80] Train loss:0.8383 acc:73.08% -- Test Loss:0.8264 acc:73.08%\n",
      "[19/80] Train loss:0.8195 acc:73.08% -- Test Loss:0.8098 acc:73.08%\n",
      "[20/80] Train loss:0.8047 acc:73.08% -- Test Loss:0.7963 acc:73.08%\n",
      "[21/80] Train loss:0.7925 acc:73.08% -- Test Loss:0.7850 acc:73.08%\n",
      "[22/80] Train loss:0.7822 acc:73.08% -- Test Loss:0.7747 acc:73.08%\n",
      "[23/80] Train loss:0.7720 acc:73.08% -- Test Loss:0.7637 acc:73.08%\n",
      "[24/80] Train loss:0.7603 acc:73.08% -- Test Loss:0.7503 acc:73.08%\n",
      "[25/80] Train loss:0.7453 acc:73.08% -- Test Loss:0.7337 acc:73.08%\n",
      "[26/80] Train loss:0.7272 acc:73.08% -- Test Loss:0.7148 acc:73.08%\n",
      "[27/80] Train loss:0.7075 acc:73.08% -- Test Loss:0.6956 acc:73.08%\n",
      "[28/80] Train loss:0.6884 acc:73.08% -- Test Loss:0.6773 acc:73.08%\n",
      "[29/80] Train loss:0.6709 acc:73.08% -- Test Loss:0.6608 acc:73.08%\n",
      "[30/80] Train loss:0.6552 acc:73.08% -- Test Loss:0.6462 acc:73.08%\n",
      "[31/80] Train loss:0.6414 acc:73.08% -- Test Loss:0.6330 acc:73.08%\n",
      "[32/80] Train loss:0.6290 acc:73.08% -- Test Loss:0.6211 acc:73.08%\n",
      "[33/80] Train loss:0.6175 acc:73.08% -- Test Loss:0.6095 acc:73.08%\n",
      "[34/80] Train loss:0.6060 acc:73.08% -- Test Loss:0.5977 acc:73.08%\n",
      "[35/80] Train loss:0.5941 acc:73.08% -- Test Loss:0.5857 acc:73.08%\n",
      "[36/80] Train loss:0.5819 acc:73.08% -- Test Loss:0.5737 acc:73.08%\n",
      "[37/80] Train loss:0.5698 acc:73.08% -- Test Loss:0.5619 acc:73.08%\n",
      "[38/80] Train loss:0.5582 acc:73.08% -- Test Loss:0.5507 acc:73.08%\n",
      "[39/80] Train loss:0.5474 acc:73.08% -- Test Loss:0.5404 acc:73.08%\n",
      "[40/80] Train loss:0.5375 acc:73.08% -- Test Loss:0.5310 acc:73.08%\n",
      "[41/80] Train loss:0.5284 acc:73.08% -- Test Loss:0.5222 acc:73.08%\n",
      "[42/80] Train loss:0.5199 acc:73.08% -- Test Loss:0.5138 acc:73.08%\n",
      "[43/80] Train loss:0.5116 acc:76.92% -- Test Loss:0.5054 acc:73.08%\n",
      "[44/80] Train loss:0.5032 acc:80.77% -- Test Loss:0.4970 acc:80.77%\n",
      "[45/80] Train loss:0.4947 acc:80.77% -- Test Loss:0.4885 acc:80.77%\n",
      "[46/80] Train loss:0.4861 acc:88.46% -- Test Loss:0.4799 acc:88.46%\n",
      "[47/80] Train loss:0.4775 acc:88.46% -- Test Loss:0.4715 acc:88.46%\n",
      "[48/80] Train loss:0.4692 acc:88.46% -- Test Loss:0.4633 acc:88.46%\n",
      "[49/80] Train loss:0.4611 acc:88.46% -- Test Loss:0.4553 acc:88.46%\n",
      "[50/80] Train loss:0.4533 acc:88.46% -- Test Loss:0.4473 acc:88.46%\n",
      "[51/80] Train loss:0.4452 acc:88.46% -- Test Loss:0.4393 acc:88.46%\n",
      "[52/80] Train loss:0.4372 acc:88.46% -- Test Loss:0.4315 acc:88.46%\n",
      "[53/80] Train loss:0.4295 acc:88.46% -- Test Loss:0.4240 acc:88.46%\n",
      "[54/80] Train loss:0.4222 acc:88.46% -- Test Loss:0.4169 acc:88.46%\n",
      "[55/80] Train loss:0.4152 acc:92.31% -- Test Loss:0.4101 acc:88.46%\n",
      "[56/80] Train loss:0.4086 acc:96.15% -- Test Loss:0.4036 acc:92.31%\n",
      "[57/80] Train loss:0.4022 acc:96.15% -- Test Loss:0.3972 acc:96.15%\n",
      "[58/80] Train loss:0.3958 acc:96.15% -- Test Loss:0.3908 acc:96.15%\n",
      "[59/80] Train loss:0.3894 acc:96.15% -- Test Loss:0.3844 acc:96.15%\n",
      "[60/80] Train loss:0.3830 acc:96.15% -- Test Loss:0.3781 acc:96.15%\n",
      "[61/80] Train loss:0.3767 acc:96.15% -- Test Loss:0.3719 acc:96.15%\n",
      "[62/80] Train loss:0.3705 acc:96.15% -- Test Loss:0.3658 acc:96.15%\n",
      "[63/80] Train loss:0.3645 acc:96.15% -- Test Loss:0.3598 acc:96.15%\n",
      "[64/80] Train loss:0.3585 acc:96.15% -- Test Loss:0.3540 acc:96.15%\n",
      "[65/80] Train loss:0.3527 acc:100.00% -- Test Loss:0.3482 acc:96.15%\n",
      "[66/80] Train loss:0.3469 acc:100.00% -- Test Loss:0.3424 acc:96.15%\n",
      "[67/80] Train loss:0.3412 acc:100.00% -- Test Loss:0.3368 acc:100.00%\n",
      "[68/80] Train loss:0.3355 acc:100.00% -- Test Loss:0.3311 acc:100.00%\n",
      "[69/80] Train loss:0.3300 acc:100.00% -- Test Loss:0.3256 acc:100.00%\n",
      "[70/80] Train loss:0.3245 acc:100.00% -- Test Loss:0.3202 acc:100.00%\n",
      "[71/80] Train loss:0.3191 acc:100.00% -- Test Loss:0.3150 acc:100.00%\n",
      "[72/80] Train loss:0.3139 acc:100.00% -- Test Loss:0.3099 acc:100.00%\n",
      "[73/80] Train loss:0.3089 acc:100.00% -- Test Loss:0.3049 acc:100.00%\n",
      "[74/80] Train loss:0.3039 acc:100.00% -- Test Loss:0.2999 acc:100.00%\n",
      "[75/80] Train loss:0.2990 acc:100.00% -- Test Loss:0.2951 acc:100.00%\n",
      "[76/80] Train loss:0.2941 acc:100.00% -- Test Loss:0.2903 acc:100.00%\n",
      "[77/80] Train loss:0.2894 acc:100.00% -- Test Loss:0.2856 acc:100.00%\n",
      "[78/80] Train loss:0.2847 acc:100.00% -- Test Loss:0.2810 acc:100.00%\n",
      "[79/80] Train loss:0.2801 acc:100.00% -- Test Loss:0.2765 acc:100.00%\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 80\n",
    "for epoch in range(max_epochs):\n",
    "    tr_loss, tr_acc = train()\n",
    "    eva_loss, eva_acc = evaluate()\n",
    "    print('[{}/{}] Train loss:{:.4f} acc:{:.2f}% -- Test Loss:{:.4f} acc:{:.2f}%'.format(\n",
    "        epoch, max_epochs, tr_loss,tr_acc*100, eva_loss, eva_acc*100\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90535c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
