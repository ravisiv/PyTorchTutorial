{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91a9fe3",
   "metadata": {},
   "source": [
    "## Iris Dataset classification prediction using PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0ba658",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "Thanks for excellent tutorial for Pytorch!\n",
    "https://www.youtube.com/watch?v=lfQs6JEkhTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a374946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55f317ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9c3e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x107636eb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1239\n",
    "torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c8068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    torch.cuda.manual_seed(SEED)  #will it work?\n",
    "\n",
    "    \n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efd7b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= ['slength','swidth','plength','pwidth'] + ['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90501012",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "687bd851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   slength  150 non-null    float32\n",
      " 1   swidth   150 non-null    float32\n",
      " 2   plength  150 non-null    float32\n",
      " 3   pwidth   150 non-null    float32\n",
      " 4   class    150 non-null    float32\n",
      "dtypes: float32(5)\n",
      "memory usage: 3.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae80430",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df.index)\n",
    "new_indices = np.random.permutation(n)\n",
    "df = df.iloc[new_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdd38b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df ['class']\n",
    "X = df.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "463d1531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "270abe6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1591729e+00, -1.3197948e-01,  9.9010795e-01,  1.1855671e+00],\n",
       "       [ 1.6438439e+00,  3.2841417e-01,  1.2742952e+00,  7.9067063e-01],\n",
       "       [-1.7367418e-01, -1.2829634e+00,  7.0592082e-01,  1.0539351e+00],\n",
       "       [-4.1600969e-01, -1.0527668e+00,  3.6489633e-01,  8.7762193e-04],\n",
       "       [-1.1430168e+00,  1.2492008e+00, -1.3402265e+00, -1.4470764e+00],\n",
       "       [-1.1430168e+00,  9.8217063e-02, -1.2833891e+00, -1.3154444e+00],\n",
       "       [-2.9484195e-01, -3.6217603e-01, -8.9803182e-02,  1.3250968e-01],\n",
       "       [ 3.1099743e-01, -5.9237313e-01,  5.3540844e-01,  8.7762193e-04],\n",
       "       [ 2.4920194e+00,  1.7095945e+00,  1.5016450e+00,  1.0539351e+00],\n",
       "       [ 6.8661921e-02,  3.2841417e-01,  5.9224612e-01,  7.9067063e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "659bf9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), y.to_numpy(),\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a1d3aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape\n",
    "x_shape = X_train.shape\n",
    "y_shape = y_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d82271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = x_shape[1]\n",
    "output_size = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c19f891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3\n"
     ]
    }
   ],
   "source": [
    "print(input_size,output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d0a0e8",
   "metadata": {},
   "source": [
    "## Dataset Class\n",
    "\n",
    "The dataset class defines a class where data exists. It has two types, test dataset and train dataset. Each type will hold the corresponding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14653202",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, data,label):\n",
    "        assert len(data) == len(label)\n",
    "        \n",
    "        self.data = torch.from_numpy(data)\n",
    "        self.label =torch.from_numpy(label)\n",
    "        \n",
    "    def __getitem__ (self,index):\n",
    "        return self.data[index], self.label[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac7b8cf",
   "metadata": {},
   "source": [
    "#### Load data to dataloader dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b693828",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = IrisDataset(X_train,y_train)\n",
    "test_data = IrisDataset(X_test,y_test)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size = 64,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size = 64,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76531dc6",
   "metadata": {},
   "source": [
    "### Create neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023d9d04",
   "metadata": {},
   "source": [
    "#### Attach to MPS (Metal), else CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fc1c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab343316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f70f857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisNeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.fn1 = nn.Linear(input_size,6)\n",
    "        self.fn2 = nn.Linear(6,output_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fn1(x))\n",
    "        x = self.fn2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e8fe455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IrisNeuralNetwork(\n",
       "  (fn1): Linear(in_features=4, out_features=6, bias=True)\n",
       "  (fn2): Linear(in_features=6, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = IrisNeuralNetwork()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fead2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9031,  0.1955,  1.9378],\n",
      "        [ 1.7876,  0.2963,  1.9375],\n",
      "        [ 1.1618,  0.2885,  2.1160],\n",
      "        [ 1.6410,  0.2266,  1.9201],\n",
      "        [ 1.6470, -0.0170,  1.9157]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(train_dataloader))\n",
    "x = x[:5].to(device)\n",
    "score = model(x)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd7af8",
   "metadata": {},
   "source": [
    "## Loss Function and Optimizer\n",
    "\n",
    "Cross Entropy Loss and Adam Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39bcb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01, weight_decay = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bdac2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    \n",
    "    for x,y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        n = x.size(0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        score = model(x)\n",
    "        y_long = y.type(torch.LongTensor)\n",
    "        loss = loss_function(score,y_long)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        predictions = score.max(1, keepdim=True)[1]\n",
    "        num_correct = predictions.eq(y.view_as(predictions)).sum().item()\n",
    "        \n",
    "    accuracy = num_correct /n\n",
    "    return loss, accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9d7673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x,y in test_dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            n = x.size(0)\n",
    "\n",
    "            score = model(x)\n",
    "            y_long = y.type(torch.LongTensor)\n",
    "            loss = loss_function(score,y_long)\n",
    "\n",
    "            predictions = score.max(1, keepdim=True)[1]\n",
    "            num_correct = predictions.eq(y.view_as(predictions)).sum().item()\n",
    "        \n",
    "    accuracy = num_correct /n \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66d4d76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/80] Train loss:1.3220 acc:3.85% -- Test Loss:1.2136 acc:26.92%\n",
      "[1/80] Train loss:1.1661 acc:46.15% -- Test Loss:1.1273 acc:38.46%\n",
      "[2/80] Train loss:1.1361 acc:15.38% -- Test Loss:1.1329 acc:26.92%\n",
      "[3/80] Train loss:1.1405 acc:26.92% -- Test Loss:1.1172 acc:26.92%\n",
      "[4/80] Train loss:1.0984 acc:23.08% -- Test Loss:1.0635 acc:15.38%\n",
      "[5/80] Train loss:1.0407 acc:26.92% -- Test Loss:1.0143 acc:57.69%\n",
      "[6/80] Train loss:1.0012 acc:57.69% -- Test Loss:0.9879 acc:57.69%\n",
      "[7/80] Train loss:0.9836 acc:57.69% -- Test Loss:0.9775 acc:57.69%\n",
      "[8/80] Train loss:0.9766 acc:57.69% -- Test Loss:0.9722 acc:57.69%\n",
      "[9/80] Train loss:0.9720 acc:57.69% -- Test Loss:0.9675 acc:57.69%\n",
      "[10/80] Train loss:0.9681 acc:57.69% -- Test Loss:0.9639 acc:57.69%\n",
      "[11/80] Train loss:0.9659 acc:57.69% -- Test Loss:0.9616 acc:57.69%\n",
      "[12/80] Train loss:0.9637 acc:57.69% -- Test Loss:0.9573 acc:53.85%\n",
      "[13/80] Train loss:0.9566 acc:42.31% -- Test Loss:0.9458 acc:50.00%\n",
      "[14/80] Train loss:0.9405 acc:42.31% -- Test Loss:0.9252 acc:53.85%\n",
      "[15/80] Train loss:0.9160 acc:57.69% -- Test Loss:0.8988 acc:65.38%\n",
      "[16/80] Train loss:0.8882 acc:69.23% -- Test Loss:0.8716 acc:69.23%\n",
      "[17/80] Train loss:0.8615 acc:69.23% -- Test Loss:0.8470 acc:73.08%\n",
      "[18/80] Train loss:0.8383 acc:73.08% -- Test Loss:0.8264 acc:73.08%\n",
      "[19/80] Train loss:0.8195 acc:73.08% -- Test Loss:0.8098 acc:73.08%\n",
      "[20/80] Train loss:0.8047 acc:73.08% -- Test Loss:0.7963 acc:73.08%\n",
      "[21/80] Train loss:0.7925 acc:73.08% -- Test Loss:0.7850 acc:73.08%\n",
      "[22/80] Train loss:0.7822 acc:73.08% -- Test Loss:0.7747 acc:73.08%\n",
      "[23/80] Train loss:0.7720 acc:73.08% -- Test Loss:0.7637 acc:73.08%\n",
      "[24/80] Train loss:0.7603 acc:73.08% -- Test Loss:0.7503 acc:73.08%\n",
      "[25/80] Train loss:0.7453 acc:73.08% -- Test Loss:0.7337 acc:73.08%\n",
      "[26/80] Train loss:0.7272 acc:73.08% -- Test Loss:0.7148 acc:73.08%\n",
      "[27/80] Train loss:0.7075 acc:73.08% -- Test Loss:0.6956 acc:73.08%\n",
      "[28/80] Train loss:0.6884 acc:73.08% -- Test Loss:0.6773 acc:73.08%\n",
      "[29/80] Train loss:0.6709 acc:73.08% -- Test Loss:0.6608 acc:73.08%\n",
      "[30/80] Train loss:0.6552 acc:73.08% -- Test Loss:0.6462 acc:73.08%\n",
      "[31/80] Train loss:0.6414 acc:73.08% -- Test Loss:0.6330 acc:73.08%\n",
      "[32/80] Train loss:0.6290 acc:73.08% -- Test Loss:0.6211 acc:73.08%\n",
      "[33/80] Train loss:0.6175 acc:73.08% -- Test Loss:0.6095 acc:73.08%\n",
      "[34/80] Train loss:0.6060 acc:73.08% -- Test Loss:0.5977 acc:73.08%\n",
      "[35/80] Train loss:0.5941 acc:73.08% -- Test Loss:0.5857 acc:73.08%\n",
      "[36/80] Train loss:0.5819 acc:73.08% -- Test Loss:0.5737 acc:73.08%\n",
      "[37/80] Train loss:0.5698 acc:73.08% -- Test Loss:0.5619 acc:73.08%\n",
      "[38/80] Train loss:0.5582 acc:73.08% -- Test Loss:0.5507 acc:73.08%\n",
      "[39/80] Train loss:0.5474 acc:73.08% -- Test Loss:0.5404 acc:73.08%\n",
      "[40/80] Train loss:0.5375 acc:73.08% -- Test Loss:0.5310 acc:73.08%\n",
      "[41/80] Train loss:0.5284 acc:73.08% -- Test Loss:0.5222 acc:73.08%\n",
      "[42/80] Train loss:0.5199 acc:73.08% -- Test Loss:0.5138 acc:73.08%\n",
      "[43/80] Train loss:0.5116 acc:76.92% -- Test Loss:0.5054 acc:73.08%\n",
      "[44/80] Train loss:0.5032 acc:80.77% -- Test Loss:0.4970 acc:80.77%\n",
      "[45/80] Train loss:0.4947 acc:80.77% -- Test Loss:0.4885 acc:80.77%\n",
      "[46/80] Train loss:0.4861 acc:88.46% -- Test Loss:0.4799 acc:88.46%\n",
      "[47/80] Train loss:0.4775 acc:88.46% -- Test Loss:0.4715 acc:88.46%\n",
      "[48/80] Train loss:0.4692 acc:88.46% -- Test Loss:0.4633 acc:88.46%\n",
      "[49/80] Train loss:0.4611 acc:88.46% -- Test Loss:0.4553 acc:88.46%\n",
      "[50/80] Train loss:0.4533 acc:88.46% -- Test Loss:0.4473 acc:88.46%\n",
      "[51/80] Train loss:0.4452 acc:88.46% -- Test Loss:0.4393 acc:88.46%\n",
      "[52/80] Train loss:0.4372 acc:88.46% -- Test Loss:0.4315 acc:88.46%\n",
      "[53/80] Train loss:0.4295 acc:88.46% -- Test Loss:0.4240 acc:88.46%\n",
      "[54/80] Train loss:0.4222 acc:88.46% -- Test Loss:0.4169 acc:88.46%\n",
      "[55/80] Train loss:0.4152 acc:92.31% -- Test Loss:0.4101 acc:88.46%\n",
      "[56/80] Train loss:0.4086 acc:96.15% -- Test Loss:0.4036 acc:92.31%\n",
      "[57/80] Train loss:0.4022 acc:96.15% -- Test Loss:0.3972 acc:96.15%\n",
      "[58/80] Train loss:0.3958 acc:96.15% -- Test Loss:0.3908 acc:96.15%\n",
      "[59/80] Train loss:0.3894 acc:96.15% -- Test Loss:0.3844 acc:96.15%\n",
      "[60/80] Train loss:0.3830 acc:96.15% -- Test Loss:0.3781 acc:96.15%\n",
      "[61/80] Train loss:0.3767 acc:96.15% -- Test Loss:0.3719 acc:96.15%\n",
      "[62/80] Train loss:0.3705 acc:96.15% -- Test Loss:0.3658 acc:96.15%\n",
      "[63/80] Train loss:0.3645 acc:96.15% -- Test Loss:0.3598 acc:96.15%\n",
      "[64/80] Train loss:0.3585 acc:96.15% -- Test Loss:0.3540 acc:96.15%\n",
      "[65/80] Train loss:0.3527 acc:100.00% -- Test Loss:0.3482 acc:96.15%\n",
      "[66/80] Train loss:0.3469 acc:100.00% -- Test Loss:0.3424 acc:96.15%\n",
      "[67/80] Train loss:0.3412 acc:100.00% -- Test Loss:0.3368 acc:100.00%\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 80\n",
    "for epoch in range(max_epochs):\n",
    "    tr_loss, tr_acc = train()\n",
    "    eva_loss, eva_acc = evaluate()\n",
    "    \n",
    "        \n",
    "    print('[{}/{}] Train loss:{:.4f} acc:{:.2f}% -- Test Loss:{:.4f} acc:{:.2f}%'.format(\n",
    "        epoch, max_epochs, tr_loss,tr_acc*100, eva_loss, eva_acc*100\n",
    "    ))\n",
    "    \n",
    "    if eva_acc >= 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c0bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
